{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Titanic Project\n",
    "The goal is to correctly predict if someone survived the Titanic shipwreck. At the end I created a web API to predict which passengers died or not.\n",
    "\n",
    "**Best results : 83.7 % accuracy**\n",
    "\n",
    "## Overview\n",
    "### 1) Data Exploration and Cleaning\n",
    "\n",
    "### 2) Feature Engineering\n",
    "\n",
    "### 3) Data Preprocessing for Model\n",
    "\n",
    "### 4) Basic Model Building\n",
    "\n",
    "### 5) Model Tuning\n",
    "\n",
    "### 6) Ensemble Model Building\n",
    "\n",
    "### 7) Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, learning_curve\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score\n",
    "\n",
    "# custom estimator\n",
    "from custom_estimators import FeatureSelector, IsAlone, ExtractName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sns.set(style = 'ticks')\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.dpi'] = 144"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data Exploration and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "First we load the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('titanic/train.csv')\n",
    "test = pd.read_csv('titanic/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Observations and Assumptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Checking basic info on the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train.info(), print(), test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Checking missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train.isna().any(), print(), test.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Variables with missing values:**\n",
    "train: *Age, Cabin and Embarked*\n",
    "test: *Age, Fare and Cabin*\n",
    "Let us continue to find out more about missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def count_na(df, columns):\n",
    "    '''\n",
    "    Count the missing values by column.\n",
    "\n",
    "    Parameters:\n",
    "        df: dataframe\n",
    "        columns: columns of the dataframe\n",
    "    Returns: Number of missing values by column\n",
    "    '''\n",
    "\n",
    "    counts = [(df[col].isna() == 1).sum() for col in columns]\n",
    "    print([(columns[i], counts[i]) for i in range(len(columns))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Number of missing values in train_data\n",
    "count_na(train, ['Age', 'Cabin', 'Embarked'])\n",
    "\n",
    "#Number of missing values in test_data\n",
    "count_na(test, ['Age', 'Cabin', 'Fare'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train.describe(include = ['O'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train['train_test'] = 1\n",
    "test['train_test'] = 0\n",
    "test['Survived'] = np.NaN\n",
    "whole_data = pd.concat([train,test])\n",
    "\n",
    "%matplotlib inline\n",
    "whole_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train.describe().columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data Exploration and cleaning\n",
    "#### 1) We compare each feature with the survived column to see how it affected the survival of the passengers.\n",
    "\n",
    "#### 2) First seperate the columns into categorical and numerical and look at them individually.\n",
    "\n",
    "#### 3) Look at correlations in the data.\n",
    "\n",
    "#### 4) For each column, look at the records in it that survived or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 1) We compare each feature with the survived column to see how it affected the survival of the passengers.\n",
    "### Pclass vs. Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train[['Pclass', 'Survived']].groupby('Pclass').mean().sort_values(by='Survived', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Passengers in 1st class are more likely to survive by 62.9% more than others apparently. Always when you can buy first class tickets :)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Fare vs. Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train.Fare.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(train, col = 'Survived')\n",
    "g = g.map(sns.histplot, 'Fare', bins = 50, kde = False)\n",
    "g.set_axis_labels('Fare $','Number')\n",
    "g.fig.subplots_adjust(top = 0.8)\n",
    "g.fig.suptitle(\"Fare vs. Survived\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Sex vs. Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train[['Sex', 'Survived']].groupby('Sex').mean().sort_values('Survived', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Females have a higher chance of surviving than males."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### Age vs. Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ticks = [i for i in np.arange(0, 90, 10)]\n",
    "g = sns.FacetGrid(train, col = 'Survived')\n",
    "g = g.map(sns.histplot, 'Age', bins = 50, kde= True)\n",
    "g.set(xticks = ticks)\n",
    "g.set_axis_labels('Age','Probability')\n",
    "g.fig.subplots_adjust(top = 0.8)\n",
    "g.fig.suptitle(\"Age vs. Survived\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "From 0-10 years, passengers mostly survived.\n",
    "From 20 - 40 years, passengers mostly died.\n",
    "At 75+ years, it seems like all of them survived. We will keep 'Age' in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sns.barplot(x = train['SibSp'], y = train['Survived'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "It seems like the more you had siblings or spouses, the lesser chances to survive you had excluding 0 sibsp which is a little lower. Anyway let's continue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Parch vs. Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sns.barplot(x = train['Parch'], y = train['Survived'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "It seems like travelling alone wasn't recommended either because those with parch = 0 and sibsp = 0 have low survival rates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Embarked vs. Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train[['Embarked', 'Survived']].groupby('Embarked').mean().sort_values(by = 'Survived', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Cherbourg passengers survived at a better rate than the rest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Sex, Pclass, Embarked vs. Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(train, col = 'Embarked')\n",
    "g.map(sns.pointplot,'Pclass' ,'Survived', 'Sex', palette = 'bright')\n",
    "g.fig.subplots_adjust(top = 0.8)\n",
    "g.fig.suptitle(\"Sex, Pclass, Embarked vs. Survived\")\n",
    "g.add_legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "644 passengers embarked at S(most of them) so in average males have a lower survival rate than females."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Age, Pclass vs. Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(train, row = 'Pclass', col = 'Survived')\n",
    "g.map(plt.hist, 'Age')\n",
    "g.fig.subplots_adjust(top = 0.9)\n",
    "g.fig.suptitle(\"Age, Pclass vs. Survived\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The 3rd class has the highest casualties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sns.heatmap(train[['Survived', 'Age', 'SibSp', 'Parch', 'Fare']].corr(), annot=True, cmap='RdYlGn')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Since SipSp and Parch seem to be somewhat correlated, we remove them to reduce the noise in our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We extract each passenger's title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "title = [i.split(\",\")[1].split(\".\")[0].strip() for i in train[\"Name\"]]\n",
    "title = Counter(title)\n",
    "title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's categorize it as follows:\n",
    "* Mr/Master: 0\n",
    "* Mrs/Miss: 1\n",
    "* Others: 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Here is what we are going to do for the feature engineering.**\n",
    "\n",
    "1. Drop out\n",
    "    PassengerId(irrelevant),\n",
    "    Name(feature engineered),\n",
    "    Ticket(irrelevant) and\n",
    "    Cabin(irrelevant and too many NaNs).\n",
    "2. Create a new feature 'IsAlone'( = SibSp + Parch + 1) to indicate if a passenger is alone.\n",
    "3. Extract titles from Name.\n",
    "4. Missing value imputation and normalization for numerical features.\n",
    "5. Encode the categorical features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**All feature transformers are done in custom_estimators.py.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Creating the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 'Embarked' has only two missing values\n",
    "train['Embarked'].fillna(value = train['Embarked'].value_counts().index[0], inplace=True)\n",
    "X = train.drop('Survived', axis = 1)\n",
    "y = train['Survived']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "num_columns = ['Age', 'Fare']\n",
    "cat_columns = ['Pclass', 'Sex', 'Embarked', 'IsAlone', 'Title'] # We will create the features 'IsAlone' and 'Title'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "num_pipe = Pipeline([('num_selector', FeatureSelector(num_columns)),\n",
    "                     ('imputer', SimpleImputer(strategy = 'median')),\n",
    "                     ('Normalization', StandardScaler())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cat_pipe = Pipeline([('cat_selector', FeatureSelector(cat_columns)),\n",
    "                     ('ohe', OneHotEncoder(sparse = False))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "union = FeatureUnion([('num', num_pipe),\n",
    "                      ('cat', cat_pipe)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "learning_curve_pipe = Pipeline([('IsAlone', IsAlone(\"SibSp\", \"Parch\", 'IsAlone')),\n",
    "                                ('Title', ExtractName('Title')),\n",
    "                                ('union', union)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Plotting the learning curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Here we select a couple of classifiers to see the learning curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "learning_curve_pipe = Pipeline([('IsAlone', IsAlone(\"SibSp\", \"Parch\", 'IsAlone')),\n",
    "                                ('Title', ExtractName('Title')),\n",
    "                                ('union', union)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_curve = learning_curve_pipe.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_learning_curve(clf, title, X, y):\n",
    "    '''\n",
    "    Plot the test and training learning curve.\n",
    "\n",
    "    Parameters:\n",
    "        clf: estimator\n",
    "        title: graph title\n",
    "    Returns:\n",
    "        Learning curve\n",
    "    '''\n",
    "\n",
    "    train_sizes,train_scores,test_scores = learning_curve(clf,X,y,random_state = 42,cv = 20, shuffle = True)\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "\n",
    "    ylim = (0.7, 1.01)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "        label=\"Training score | Avg: {}\".format(str(round(train_scores_mean.mean(), 2))))\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "        label=\"Cross-validation score | Avg: {}\".format(str(round(test_scores_mean.mean(), 2))))\n",
    "\n",
    "\n",
    "    plt.title(title)\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_learning_curve(LogisticRegression(solver = 'lbfgs'),'Learning Curve of Logistic Regression', X_curve, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_learning_curve(RandomForestClassifier(n_estimators = 100),'Learning Curve of Random Forest', X_curve, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_learning_curve(DecisionTreeClassifier(),'Learning Curve of Decision Tree', X_curve, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_learning_curve(xgb.XGBClassifier(),'Learning Curve of XGBoost', X_curve, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_learning_curve(SVC(gamma = 'scale'),'Learning Curve of SVM', X_curve, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "* Random forest, decision tree and xgboost seem to be overfitting.\n",
    "This leaves us with\n",
    "* logistic regression and\n",
    "* svm. SVM seems to have a greater average score so we will use it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Tuning the Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Here we  tune hyperparameters for SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "clf = SVC()\n",
    "\n",
    "pipe = Pipeline([('IsAlone', IsAlone(\"SibSp\", \"Parch\", 'IsAlone')),\n",
    "                 ('Title', ExtractName('Title')),\n",
    "                 ('union', union),\n",
    "                 ('classifier', clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n"
     ]
    }
   ],
   "source": [
    "param_grid  = [{'classifier__kernel': ['rbf'], 'classifier__gamma': [.1,.5,1,2,5,10],\n",
    "                                  'classifier__C': [.1, 1, 10, 100, 1000]},\n",
    "                                 {'classifier__kernel': ['linear'], 'classifier__C': [.1, 1, 10, 100, 1000]},\n",
    "                                 {'classifier__kernel': ['poly'], 'classifier__degree' : [2,3,4,5], 'classifier__C': [.1, 1, 10, 100, 1000]}]\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid, cv = 5, scoring = 'accuracy', n_jobs = None, verbose = 1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# training score and CV score\n",
    "result = \"{} is {}\"\n",
    "print(result.format(\"Training score\", grid_search.score(X_train, y_train)))\n",
    "print(result.format(\"CV score\", grid_search.best_score_))\n",
    "print(result.format(\"Best parameter\", grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Prep the submission\n",
    "y_pred = pd.Series(best_model.predict(test), name = 'Survived')\n",
    "predict = pd.DataFrame({'PassengerId': test['PassengerId'],\n",
    "                       \"Survived\": y_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Model Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We will now:\n",
    "* Build a web app using our model and Flask.\n",
    "* Then deploy it to Heroku(a cloud platform).\n",
    "* On the web app, you can enter the characteristics of a person on the titanic and then get the chances that person survived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8258427  0.80898876 0.80337079 0.82022472 0.85310734]\n",
      "0.8223068621849807\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter = 2000)\n",
    "cv = cross_val_score(lr,X_train,y_train,cv=5)\n",
    "print(cv)\n",
    "print(cv.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.75842697 0.74719101 0.8258427  0.74719101 0.8079096 ]\n",
      "0.7773122579826065\n"
     ]
    }
   ],
   "source": [
    "dt = tree.DecisionTreeClassifier(random_state = 1)\n",
    "cv = cross_val_score(dt,X_train,y_train,cv=5)\n",
    "print(cv)\n",
    "print(cv.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.75842697 0.74719101 0.8258427  0.74719101 0.8079096 ]\n",
      "0.7773122579826065\n"
     ]
    }
   ],
   "source": [
    "dt = tree.DecisionTreeClassifier(random_state = 1)\n",
    "cv = cross_val_score(dt,X_train_scaled,y_train,cv=5)\n",
    "print(cv)\n",
    "print(cv.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.76966292 0.79775281 0.80898876 0.82022472 0.85310734]\n",
      "0.8099473116231829\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "cv = cross_val_score(knn,X_train,y_train,cv=5)\n",
    "print(cv)\n",
    "print(cv.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.80337079 0.79213483 0.84831461 0.73595506 0.82485876]\n",
      "0.8009268075922046\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state = 1)\n",
    "cv = cross_val_score(rf,X_train_scaled,y_train,cv=5)\n",
    "print(cv)\n",
    "print(cv.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.85393258 0.82022472 0.8258427  0.80337079 0.86440678]\n",
      "0.8335555132355742\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(probability = True)\n",
    "cv = cross_val_score(svc,X_train_scaled,y_train,cv=5)\n",
    "print(cv)\n",
    "print(cv.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.82022472 0.81460674 0.85393258 0.79775281 0.81355932]\n",
      "0.8200152351932963\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier(random_state =1)\n",
    "cv = cross_val_score(xgb,X_train_scaled,y_train,cv=5)\n",
    "print(cv)\n",
    "print(cv.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.83707865 0.81460674 0.8258427  0.79775281 0.84745763]\n",
      "0.8245477051990097\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "voting_clf_soft = VotingClassifier(estimators = [('lr',lr),('knn',knn),('rf',rf),('gnb',gnb),('svc',svc),('xgb',xgb)], voting = 'soft')\n",
    "\n",
    "cv = cross_val_score(voting_clf_soft,X_train_scaled,y_train,cv=5)\n",
    "print(cv)\n",
    "print(cv.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.83707865 0.82022472 0.84269663 0.80337079 0.84745763]\n",
      "0.8301656827270996\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "voting_clf_hard = VotingClassifier(estimators = [('lr',lr),('knn',knn),('rf',rf),('gnb',gnb),('svc',svc),('xgb',xgb)], voting = 'hard')\n",
    "\n",
    "cv = cross_val_score(voting_clf_hard,X_train_scaled,y_train,cv=5)\n",
    "print(cv)\n",
    "print(cv.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "voting_clf_hard.fit(X_train_scaled,y_train)\n",
    "y_hat_base_vc = voting_clf_hard.predict(X_test_scaled).astype(int)\n",
    "basic_submission = {'PassengerId': test.PassengerId, 'Survived': y_hat_base_vc}\n",
    "base_submission = pd.DataFrame(data=basic_submission)\n",
    "base_submission.to_csv('base_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model Tuned Performance\n",
    "After getting the baselines, let's see if we can improve on the indivdual model results!I mainly used grid search to tune the models. I also used Randomized Search for the Random Forest and XG boosted model to simplify testing time.\n",
    "\n",
    "|Model| Baseline | Tuned Performance |\n",
    "|-----|----------|-------------------|\n",
    "|Naive Bayes| 72.2%    | NA                |\n",
    "|Logistic Regression| 82.2%    | 82.8%             |\n",
    "|Decision Tree| 77.7%    | NA                |\n",
    "|K Nearest Neighbor| 81.0%    | 82.9%             |\n",
    "|Random Forest| 80.1%    | 83.8              |\n",
    "|Support Vector Classifier| 83.4%    | 83.4%             |\n",
    "|Xtreme Gradient Boosting| 82.0%    | 82.3%             |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#simple performance reporting function\n",
    "def clf_performance(classifier, model_name):\n",
    "    print(model_name)\n",
    "    print('Best Score: ' + str(classifier.best_score_))\n",
    "    print('Best Parameters: ' + str(classifier.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "Logistic Regression\n",
      "Best Score: 0.8279375357074843\n",
      "Best Parameters: {'C': 1.623776739188721, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "param_grid = {'max_iter' : [2000],\n",
    "              'penalty' : ['l1', 'l2'],\n",
    "              'C' : np.logspace(-4, 4, 20),\n",
    "              'solver' : ['liblinear']}\n",
    "\n",
    "clf_lr = GridSearchCV(lr, param_grid = param_grid, cv = 5, verbose = True, n_jobs = None)\n",
    "best_clf_lr = clf_lr.fit(X_train_scaled,y_train)\n",
    "clf_performance(best_clf_lr,'Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "KNN\n",
      "Best Score: 0.8290611312131023\n",
      "Best Parameters: {'algorithm': 'auto', 'n_neighbors': 7, 'p': 2, 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "param_grid = {'n_neighbors' : [3,5,7,9],\n",
    "              'weights' : ['uniform', 'distance'],\n",
    "              'algorithm' : ['auto', 'ball_tree','kd_tree'],\n",
    "              'p' : [1,2]}\n",
    "clf_knn = GridSearchCV(knn, param_grid = param_grid, cv = 5, verbose = True, n_jobs= None)\n",
    "best_clf_knn = clf_knn.fit(X_train_scaled,y_train)\n",
    "clf_performance(best_clf_knn,'KNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "SVC\n",
      "Best Score: 0.8335555132355742\n",
      "Best Parameters: {'C': 1, 'gamma': 0.1}\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(probability = True)\n",
    "param_grid = tuned_parameters = [{'gamma': [.1,.5,1,2,5,10],\n",
    "                                  'C': [.1, 1, 10, 100, 1000]},\n",
    "                                 ]\n",
    "clf_svc = GridSearchCV(svc, param_grid = param_grid, cv = 5, verbose = True, n_jobs= None)\n",
    "best_clf_svc = clf_svc.fit(X_train_scaled,y_train)\n",
    "clf_performance(best_clf_svc,'SVC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 96 candidates, totalling 288 fits\n",
      "Random Forest\n",
      "Best Score: 0.834668001334668\n",
      "Best Parameters: {'bootstrap': False, 'criterion': 'gini', 'max_depth': 15, 'max_features': 10, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 400}\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=1)\n",
    "param_grid = {'n_estimators': [400, 450, 500, 550],\n",
    "              'criterion': ['gini'],\n",
    "              'bootstrap': [False],\n",
    "              'max_depth': [15, 20, 25],\n",
    "              'max_features': ['sqrt', 10],\n",
    "              'min_samples_leaf': [2, 3],\n",
    "              'min_samples_split': [2, 3]}\n",
    "\n",
    "clf_rf = GridSearchCV(rf, param_grid=param_grid, cv=3, verbose=True, n_jobs=None)\n",
    "best_clf_rf = clf_rf.fit(X_train_scaled, y_train)\n",
    "clf_performance(best_clf_rf, 'Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 243 candidates, totalling 486 fits\n",
      "XGB\n",
      "Best Score: 0.8233879947363094\n",
      "Best Parameters: {'colsample_bytree': 0.8, 'gamma': 2, 'learning_rate': 0.5, 'max_depth': None, 'min_child_weight': 0.01, 'n_estimators': 500, 'reg_alpha': 1, 'reg_lambda': 10, 'sampling_method': 'uniform', 'subsample': 0.65}\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(random_state = 1)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [450,500,550],\n",
    "    'colsample_bytree': [0.75,0.8,0.85],\n",
    "    'max_depth': [None],\n",
    "    'reg_alpha': [1],\n",
    "    'reg_lambda': [2, 5, 10],\n",
    "    'subsample': [0.55, 0.6, .65],\n",
    "    'learning_rate':[0.5],\n",
    "    'gamma':[.5,1,2],\n",
    "    'min_child_weight':[0.01],\n",
    "    'sampling_method': ['uniform']\n",
    "}\n",
    "\n",
    "clf_xgb = GridSearchCV(xgb, param_grid = param_grid, cv = 2, verbose = True, n_jobs= None)\n",
    "best_clf_xgb = clf_xgb.fit(X_train_scaled,y_train)\n",
    "clf_performance(best_clf_xgb,'XGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_rf = best_clf_rf.best_estimator_.fit(X_train_scaled,y_train)\n",
    "feat_importances = pd.Series(best_rf.feature_importances_, index=X_train_scaled.columns)\n",
    "feat_importances.nlargest(20).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model Additional Ensemble Approaches\n",
    "1) Experimented with a hard voting classifier of three estimators (KNN, SVM, RF) (81.4%)\n",
    "\n",
    "2) Experimented with a soft voting classifier of three estimators (KNN, SVM, RF) (81.7%) (best performance in competition leaderboard)\n",
    "\n",
    "3) Experimented with soft voting on all estimators performing better than 80% except xgb (KNN, RF, LR, SVC) (82.6%)\n",
    "\n",
    "4) **Experimented with soft voting on all estimators including XGB (KNN, SVM, RF, LR, XGB) (82.8%) (Best Performance)**\n",
    "\n",
    "Also wanted to test stacked ensembling but due to computational power reasons :) I will stop here for the moment. Maybe someday..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "best_knn = best_clf_knn.best_estimator_\n",
    "best_svc = best_clf_svc.best_estimator_\n",
    "best_rf = best_clf_rf.best_estimator_\n",
    "voting_clf_soft = VotingClassifier(estimators = [('knn',best_knn),('rf',best_rf),('svc',best_svc)], voting = 'soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voting_clf_hard : [0.79213483 0.81460674 0.83146067 0.79775281 0.83615819]\n",
      "voting_clf_hard mean : 0.8144226496540341\n",
      "voting_clf_soft : [0.7752809  0.8258427  0.83146067 0.79213483 0.85310734]\n",
      "voting_clf_soft mean : 0.8166888846568907\n",
      "voting_clf_all : [0.80898876 0.83146067 0.8258427  0.80337079 0.85875706]\n",
      "voting_clf_all mean : 0.8256839966990415\n",
      "voting_clf_xgb : [0.80898876 0.83146067 0.8258427  0.80898876 0.86440678]\n",
      "voting_clf_xgb mean : 0.8279375357074844\n"
     ]
    }
   ],
   "source": [
    "best_lr = best_clf_lr.best_estimator_\n",
    "best_knn = best_clf_knn.best_estimator_\n",
    "best_svc = best_clf_svc.best_estimator_\n",
    "best_rf = best_clf_rf.best_estimator_\n",
    "best_xgb = best_clf_xgb.best_estimator_\n",
    "\n",
    "voting_clf_hard = VotingClassifier(estimators = [('knn',best_knn),('rf',best_rf),('svc',best_svc)], voting = 'hard')\n",
    "voting_clf_soft = VotingClassifier(estimators = [('knn',best_knn),('rf',best_rf),('svc',best_svc)], voting = 'soft')\n",
    "voting_clf_all = VotingClassifier(estimators = [('knn',best_knn),('rf',best_rf),('svc',best_svc), ('lr', best_lr)], voting = 'soft')\n",
    "voting_clf_xgb = VotingClassifier(estimators = [('knn',best_knn),('rf',best_rf),('svc',best_svc), ('xgb', best_xgb),('lr', best_lr)], voting = 'soft')\n",
    "\n",
    "print('voting_clf_hard :',cross_val_score(voting_clf_hard,X_train,y_train,cv=5))\n",
    "print('voting_clf_hard mean :',cross_val_score(voting_clf_hard,X_train,y_train,cv=5).mean())\n",
    "\n",
    "print('voting_clf_soft :',cross_val_score(voting_clf_soft,X_train,y_train,cv=5))\n",
    "print('voting_clf_soft mean :',cross_val_score(voting_clf_soft,X_train,y_train,cv=5).mean())\n",
    "\n",
    "print('voting_clf_all :',cross_val_score(voting_clf_all,X_train,y_train,cv=5))\n",
    "print('voting_clf_all mean :',cross_val_score(voting_clf_all,X_train,y_train,cv=5).mean())\n",
    "\n",
    "print('voting_clf_xgb :',cross_val_score(voting_clf_xgb,X_train,y_train,cv=5))\n",
    "print('voting_clf_xgb mean :',cross_val_score(voting_clf_xgb,X_train,y_train,cv=5).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "VC Weights\n",
      "Best Score: 0.8369453437440487\n",
      "Best Parameters: {'weights': [1, 2, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "#in a soft voting classifier you can weight some models more than others. I used a grid search to explore different weightings on the soft xgb classifier\n",
    "#It increased score from 82.8% to 83.7%\n",
    "params = {'weights' : [[1,1,1,1,1],[2,2,2,2,1],[1,1,1,2,1],[1,2,1,1,1],[1,1,2,1,1],[1,1,1,1,2],[2,2,2,1,2]]}\n",
    "\n",
    "vote_weight = GridSearchCV(voting_clf_xgb, param_grid = params, cv = 5, verbose = True, n_jobs= None)\n",
    "best_clf_weight = vote_weight.fit(X_train_scaled,y_train)\n",
    "clf_performance(best_clf_weight,'VC Weights')\n",
    "voting_clf_sub = best_clf_weight.best_estimator_.predict(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Make Predictions\n",
    "voting_clf_hard.fit(X_train_scaled, y_train)\n",
    "voting_clf_soft.fit(X_train_scaled, y_train)\n",
    "voting_clf_all.fit(X_train_scaled, y_train)\n",
    "voting_clf_xgb.fit(X_train_scaled, y_train)\n",
    "\n",
    "best_rf.fit(X_train_scaled, y_train)\n",
    "y_hat_vc_hard = voting_clf_hard.predict(X_test_scaled).astype(int)\n",
    "y_hat_rf = best_rf.predict(X_test_scaled).astype(int)\n",
    "y_hat_vc_soft =  voting_clf_soft.predict(X_test_scaled).astype(int)\n",
    "y_hat_vc_all = voting_clf_all.predict(X_test_scaled).astype(int)\n",
    "y_hat_vc_xgb = voting_clf_xgb.predict(X_test_scaled).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#convert output to dataframe\n",
    "final_data = {'PassengerId': test.PassengerId, 'Survived': y_hat_rf}\n",
    "submission = pd.DataFrame(data=final_data)\n",
    "\n",
    "final_data_2 = {'PassengerId': test.PassengerId, 'Survived': y_hat_vc_hard}\n",
    "submission_2 = pd.DataFrame(data=final_data_2)\n",
    "\n",
    "final_data_3 = {'PassengerId': test.PassengerId, 'Survived': y_hat_vc_soft}\n",
    "submission_3 = pd.DataFrame(data=final_data_3)\n",
    "\n",
    "final_data_4 = {'PassengerId': test.PassengerId, 'Survived': y_hat_vc_all}\n",
    "submission_4 = pd.DataFrame(data=final_data_4)\n",
    "\n",
    "final_data_5 = {'PassengerId': test.PassengerId, 'Survived': y_hat_vc_xgb}\n",
    "submission_5 = pd.DataFrame(data=final_data_5)\n",
    "\n",
    "final_data_comp = {'PassengerId': test.PassengerId, 'Survived_vc_hard': y_hat_vc_hard, 'Survived_rf': y_hat_rf, 'Survived_vc_soft' : y_hat_vc_soft, 'Survived_vc_all' : y_hat_vc_all,  'Survived_vc_xgb' : y_hat_vc_xgb}\n",
    "comparison = pd.DataFrame(data=final_data_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#prepare submission files\n",
    "submission.to_csv('submission_rf.csv', index =False)\n",
    "submission_2.to_csv('submission_vc_hard.csv',index=False)\n",
    "submission_3.to_csv('submission_vc_soft.csv', index=False)\n",
    "submission_4.to_csv('submission_vc_all.csv', index=False)\n",
    "submission_5.to_csv('submission_vc_xgb2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
